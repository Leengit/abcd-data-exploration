{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b62a670",
   "metadata": {},
   "source": [
    "# An example workflow for generating hypotheses with ABCD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac779b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from Python packages\n",
    "from dipy.io.image import load_nifti, save_nifti\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc957ff-2517-43a3-833a-472feef14e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global parameters to match your environment\n",
    "gor_image_directory = \"/data2/ABCD/gor-images\"\n",
    "coregistered_images_directory = os.path.join(gor_image_directory, \"coregistered-images\")\n",
    "tabular_data_directory = \"/data2/ABCD/abcd-5.0-tabular-data-extracted\"\n",
    "core_directory = os.path.join(tabular_data_directory, \"core\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555acc8f-2c47-4aae-b015-e4bc85ea683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The locations of some useful csv data files\n",
    "file_mh_y_ksads_ss = os.path.join(\n",
    "    core_directory, \"mental-health/mh_y_ksads_ss.csv\"\n",
    ")  # see `interesting_ksads` below\n",
    "file_abcd_y_lt = os.path.join(\n",
    "    core_directory, \"abcd-general/abcd_y_lt.csv\"\n",
    ")  # site_id_l, rel_family_id, interview_age\n",
    "file_abcd_p_demo = os.path.join(\n",
    "    core_directory, \"abcd-general/abcd_p_demo.csv\"\n",
    ")  # demo_gender_id_v2(_l)?\n",
    "file_gish_p_gi = os.path.join(\n",
    "    core_directory, \"gender-identity-sexual-health/gish_p_gi.csv\"\n",
    ")  # demo_gender_id_v2(_l)?\n",
    "ph_y_bld = os.path.join(core_directory, \"physical-health/ph_y_bld.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global parameters to guide the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e45649-4472-47e0-82de-46659532de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for handling image voxel data\n",
    "\n",
    "\n",
    "def get_list_of_image_files(directory):\n",
    "    response = [\n",
    "        os.path.join(directory, file)\n",
    "        for file in os.listdir(directory)\n",
    "        if file.endswith(\".nii.gz\")\n",
    "    ]\n",
    "    return response\n",
    "\n",
    "\n",
    "def fix_filename_parsing(filename_parsing_dict):\n",
    "    if \"src_subject_id\" in filename_parsing_dict.keys():\n",
    "        filename_parsing_dict[\"src_subject_id\"] = filename_parsing_dict[\n",
    "            \"src_subject_id\"\n",
    "        ].replace(\"NDAR\", \"NDAR_\")\n",
    "    eventname_conversion = {\n",
    "        \"baselineYear1Arm1\": \"baseline_year_1_arm_1\",\n",
    "        \"1YearFollowUpYArm1\": \"1_year_follow_up_y_arm_1\",\n",
    "        \"2YearFollowUpYArm1\": \"2_year_follow_up_y_arm_1\",\n",
    "        \"3YearFollowUpYArm1\": \"3_year_follow_up_y_arm_1\",\n",
    "        \"4YearFollowUpYArm1\": \"4_year_follow_up_y_arm_1\",\n",
    "    }\n",
    "    if \"eventname\" in filename_parsing_dict.keys():\n",
    "        filename_parsing_dict[\"eventname\"] = eventname_conversion[\n",
    "            filename_parsing_dict[\"eventname\"]\n",
    "        ]\n",
    "    return filename_parsing_dict\n",
    "\n",
    "\n",
    "def get_data_from_image_files(list_of_files):\n",
    "    \"\"\"\n",
    "    get_data_from_image_files returns a list of tuples of 5 values:\n",
    "    <class 'str'>: full file name\n",
    "    <class 'dict'>: a parsing of the file name\n",
    "    <class 'numpy.ndarray'>: image data as a numpy array\n",
    "    <class 'numpy.ndarray'>: some other numpy array (transform?)\n",
    "    <class 'nibabel.nifti1.Nifti1Image'>: an object that can be modified and written to file as a .nii.gz file\n",
    "    \"\"\"\n",
    "    filename_pattern = r\"gorinput([0-9]+)-modality([0-9]+)-sub-([A-Za-z0-9]+)_ses-([A-Za-z0-9]+)_run-([A-Za-z0-9]+)_([A-Za-z0-9]+)_([A-Za-z0-9]+)-([A-Za-z0-9]+).nii.gz\"\n",
    "    filename_keys = (\n",
    "        \"gorinput\",\n",
    "        \"modality\",\n",
    "        \"src_subject_id\",\n",
    "        \"eventname\",\n",
    "        \"run\",\n",
    "        \"image_type\",\n",
    "        \"image_subtype\",\n",
    "        \"processing\",\n",
    "    )\n",
    "    response = [\n",
    "        (file,)\n",
    "        + (\n",
    "            fix_filename_parsing(\n",
    "                dict(\n",
    "                    zip(\n",
    "                        filename_keys,\n",
    "                        list(\n",
    "                            re.match(filename_pattern, os.path.basename(file)).groups()\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "        + load_nifti(file, return_img=True)\n",
    "        for file in list_of_files\n",
    "    ]\n",
    "    return response\n",
    "\n",
    "\n",
    "def select_images(image_data, key_dict):\n",
    "    # Currently we support only two keys\n",
    "    assert all(\n",
    "        [\n",
    "            key == \"src_subject_id\" or key == \"eventname\"\n",
    "            for key, value in key_dict.items()\n",
    "        ]\n",
    "    )\n",
    "    response = [\n",
    "        image_row\n",
    "        for image_row in image_data\n",
    "        if all(item in image_row.items() for item in key_dict.items())\n",
    "    ]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b07a99-3a47-47d6-9b10-4f7b257a8beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for reading and selecting data from csv files\n",
    "\n",
    "\n",
    "def _csv_file_to_list_of_lists(filename):\n",
    "    \"\"\"\n",
    "    _csv_file_to_list_of_lists returns a list of lists of str in row-major order\n",
    "    \"\"\"\n",
    "    with open(filename, mode=\"r\") as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        response = [row for row in csv_reader]\n",
    "    return response\n",
    "\n",
    "\n",
    "def _list_of_lists_to_row_dicts(list_of_lists):\n",
    "    \"\"\"\n",
    "    _list_of_lists_to_row_dicts converts a list of lists of str, in row-major order,\n",
    "    to a list of dict of str.  Each dict is formed by using the first row (column headers)\n",
    "    as keys and a given data row as values of type str.\n",
    "    \"\"\"\n",
    "    column_headers = list_of_lists[0]\n",
    "    response = [\n",
    "        {column_headers[i]: row_value for i, row_value in enumerate(row)}\n",
    "        for row in list_of_lists[1:]\n",
    "    ]\n",
    "    return response\n",
    "\n",
    "\n",
    "def csv_file_to_row_dicts(file):\n",
    "    return _list_of_lists_to_row_dicts(_csv_file_to_list_of_lists(file))\n",
    "\n",
    "\n",
    "def select_items(list_of_row_dicts, key_dict):\n",
    "    \"\"\"\n",
    "    select_items returns all rows (i.e., top-level elements) of list_of_row_dicts, a list of dict of str,\n",
    "    for which the row (a dict) contains all of the items in key_dict.\n",
    "    \"\"\"\n",
    "    response = [\n",
    "        row_dict\n",
    "        for row_dict in list_of_row_dicts\n",
    "        if all(item in row_dict.items() for item in key_dict.items())\n",
    "    ]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feed3d2-6580-4e09-9dfe-cfb78e2e1ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for computing summary statistics for csv data\n",
    "\n",
    "\n",
    "def row_dicts_to_counts_for_each_column(row_dicts):\n",
    "    column_dict = {key: dict() for row in row_dicts for key in row.keys()}\n",
    "    for row in row_dicts:\n",
    "        for column_header, value in row.items():\n",
    "            # column_dict[column_header] = column_dict.get(column_header, dict())\n",
    "            if value == \"555\" or value == \"888\":\n",
    "                value = \"\"\n",
    "            column_dict[column_header][value] = (\n",
    "                column_dict[column_header].get(value, 0) + 1\n",
    "            )\n",
    "    # Sort each value dict by its keys for easier reading\n",
    "    column_dict = {\n",
    "        key: dict(sorted(value.items(), key=lambda item: item[0], reverse=False))\n",
    "        for key, value in column_dict.items()\n",
    "    }\n",
    "    return column_dict\n",
    "\n",
    "\n",
    "def entropy_of_column_counts(column_counts):\n",
    "    assert all(value >= 0 for value in column_counts.values())\n",
    "    total_count = sum(column_counts.values())\n",
    "    entropy = sum(\n",
    "        [\n",
    "            count / total_count * math.log2(total_count / count)\n",
    "            for count in column_counts.values()\n",
    "            if count > 0\n",
    "        ]\n",
    "    )\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def entropy_of_all_columns(all_columns):\n",
    "    return {\n",
    "        key: entropy_of_column_counts(value)\n",
    "        for key, value in all_columns.items()\n",
    "        if bool(re.match(\"ksads_\\d\", key))\n",
    "    }\n",
    "\n",
    "\n",
    "def find_interesting_entropies(file_mh_y_ksads_ss):\n",
    "    # Find some KSADS data columns with high entropy.\n",
    "    # TODO: Should we be treating the value '888' or '' specially?\n",
    "    row_dicts_mh_y_ksads_ss = csv_file_to_row_dicts(file_mh_y_ksads_ss)\n",
    "    print(\"Read done\")\n",
    "\n",
    "    counts_for_each_column_mh_y_ksads_ss = row_dicts_to_counts_for_each_column(\n",
    "        row_dicts_mh_y_ksads_ss\n",
    "    )\n",
    "    print(\"Column counting done\")\n",
    "\n",
    "    entropies = entropy_of_all_columns(counts_for_each_column_mh_y_ksads_ss)\n",
    "    sorted_entropies = dict(\n",
    "        sorted(entropies.items(), key=lambda item: item[1], reverse=True)\n",
    "    )\n",
    "    sorted_entropies = {\n",
    "        key: (value, counts_for_each_column_mh_y_ksads_ss[key])\n",
    "        for key, value in sorted_entropies.items()\n",
    "        if bool(re.match(\"ksads_\\d\", key))\n",
    "    }\n",
    "    print(\"Entropy calculation done\")\n",
    "    return sorted_entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d841f51-7690-4152-8e78-0bff309e4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find interesting KSADS data\n",
    "\n",
    "if True:\n",
    "    # We want to re-compute interesting_ksads\n",
    "    try:\n",
    "        sorted_entropies\n",
    "        print(\"Using cached value for sorted_entropies\")\n",
    "    except NameError:\n",
    "        # find_interesting_entropies is slow, so only compute sorted_entropies if we haven't already\n",
    "        sorted_entropies = find_interesting_entropies(file_mh_y_ksads_ss)\n",
    "    number_wanted = 20\n",
    "    # print(f\"Distribution details: {list(sorted_entropies.items())[:number_wanted]}\")\n",
    "    interesting_ksads = list(sorted_entropies.keys())[:number_wanted]\n",
    "    print(f\"{interesting_ksads = }\")\n",
    "else:\n",
    "    # Previous expression returns\n",
    "    interesting_ksads = [\n",
    "        \"ksads_22_142_t\",  # Symptom - Insomnia, Past\n",
    "        \"ksads_22_970_t\",  # Diagnosis - SLEEP PROBLEMS, Past\n",
    "        \"ksads_2_11_t\",  # Symptom - Explosive Irritability, Past\n",
    "        \"ksads_1_2_t\",  # Symptom - Depressed Mood, Past\n",
    "        \"ksads_2_13_t\",  # Symptom - Decreased Need for Sleep, Past\n",
    "        \"ksads_1_6_t\",  # Symptom - Anhedonia, Past\n",
    "        \"ksads_22_141_t\",  # Symptom - Insomnia, Present\n",
    "        \"ksads_22_969_t\",  # Diagnosis - SLEEP PROBLEMS, Present\n",
    "        \"ksads_2_8_t\",  # Symptom - Elevated Mood, Past\n",
    "        \"ksads_10_46_t\",  # Symptom - Excessive worries more days than not Past\n",
    "        \"ksads_1_4_t\",  # Symptom - Irritability, Past\n",
    "        \"ksads_2_10_t\",  # Symptom - ExplosiveIrritability, PresentNext\n",
    "        \"ksads_8_31_t\",  # Symptom - Fear of Social Situations, Past\n",
    "        \"ksads_23_146_t\",  # Symptom - Wishes/Better off dead, Past\n",
    "        \"ksads_23_957_t\",  # Diagnosis - SuicidalideationPassivePast\n",
    "        \"ksads_1_5_t\",  # Symptom - Anhedonia, Present\n",
    "        \"ksads_2_839_t\",  # Diagnosis - Unspecified Bipolar and Related Disorder, PAST (F31.9)\n",
    "        \"ksads_2_833_t\",  # Diagnosis - Bipolar I Disorder, most recent past episode manic (F31.1x)\n",
    "        \"ksads_1_3_t\",  # Symptom - Irritability, Present\n",
    "        \"ksads_1_842_t\",  # Diagnosis - Major Depressive Disorder, Past (F32.9)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8eab6d-8552-4e5f-b9d5-2a918b53e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A random subset of all image files\n",
    "list_of_image_files = random.sample(\n",
    "    get_list_of_image_files(coregistered_images_directory), 10\n",
    ")\n",
    "image_data = get_data_from_image_files(list_of_image_files)\n",
    "print(f\"file name parsing = {[image[1] for image in image_data]!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7204521-f511-4be1-8cdb-6ba70452794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(f\"{len(image_data) = }\")\n",
    "    print(f\"{type(image_data[0]) = }\")\n",
    "    print(f\"{len(image_data[0]) = }\")\n",
    "    print(\"types(image_data[0]) = \", [type(e) for e in image_data[0]])\n",
    "    print(f\"{image_data[0][0] = }\")\n",
    "    print(f\"{image_data[0][1] = }\")\n",
    "    print(f\"{image_data[0][2].shape = }\")\n",
    "    print(f\"{image_data[0][3].shape = }\")\n",
    "if False:\n",
    "    print(f\"{type(list_of_lists) = }\")\n",
    "    print(f\"{type(list_of_lists[0]) = }\")\n",
    "    # print(\"csv_data row lengths = \", [len(row) for row in list_of_lists])\n",
    "    # print(\"Column 0 = \", [row[0] for row in list_of_lists])\n",
    "    print(\"Corner value = \", list_of_lists[0][0])\n",
    "if False:\n",
    "    print(f\"{type(row_dicts) = }\")\n",
    "    key0 = 0\n",
    "    value0 = row_dicts[key0]\n",
    "    key1 = next(iter(value0))\n",
    "    value1 = value0[key1]\n",
    "    print(f\"row_dicts[{key0!r}][{key1!r}] = {value1!r}\")\n",
    "    # print(f\"{row_dicts[0] = }\")\n",
    "    dict_of_keys = {key1: value1}\n",
    "    print(f\"{dict_of_keys = }\")\n",
    "    items = select_items(row_dicts, dict_of_keys)\n",
    "    print(f\"{len(items) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57674d6e-f7e4-441c-99f7-57949fe641b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "abcd311",
   "language": "python",
   "name": "abcd311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
